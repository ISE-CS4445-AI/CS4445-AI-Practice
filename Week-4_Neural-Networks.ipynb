{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Exercise Notebook: Neural Networks with PyTorch\n",
    "\n",
    "This notebook is split into two parts:\n",
    "1. **Introduction to PyTorch** – Learn the basics.\n",
    "2. **Neural Network Implementations** – Build custom nets, established architectures, and use pretrained networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction to PyTorch\n",
    "\n",
    "In this section we cover the basics. We learn how to create and work with tensors. We check for GPU support. Run each cell and follow the instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Importing PyTorch and Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Print the PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Create a simple tensor\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(\"Tensor x:\", x)\n",
    "\n",
    "# Create a random tensor with shape (3, 3)\n",
    "rand_tensor = torch.rand(3, 3)\n",
    "print(\"Random Tensor:\\n\", rand_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Basic Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two tensors\n",
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([3, 4])\n",
    "\n",
    "# Addition\n",
    "sum_ab = a + b\n",
    "print(\"Sum:\", sum_ab)\n",
    "\n",
    "# Element-wise multiplication\n",
    "prod_ab = a * b\n",
    "print(\"Element-wise Product:\", prod_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Check for GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the device: use GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Move tensor 'x' to the selected device\n",
    "x = x.to(device)\n",
    "print(\"Tensor x on device:\", x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Neural Network Implementations\n",
    "\n",
    "In this section we build and experiment with neural networks.\n",
    "We cover:\n",
    "- A custom neural network.\n",
    "- An established architecture (LeNet).\n",
    "- A pretrained network (ResNet18)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Custom Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple feed-forward network for, e.g., MNIST (28x28 images flattened to 784)\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of CustomNet\n",
    "model = CustomNet(input_size=784, hidden_size=128, num_classes=10)\n",
    "print(\"CustomNet Architecture:\\n\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Established Architecture: LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet was designed for handwritten digit recognition.\n",
    "# This is a simplified implementation.\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Convolution layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply first conv + ReLU + pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Apply second conv + ReLU + pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of LeNet\n",
    "lenet_model = LeNet()\n",
    "print(\"LeNet Architecture:\\n\", lenet_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Pretrained Networks: ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load a pretrained ResNet18 model from torchvision.\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "# Set the model to evaluation mode\n",
    "resnet18.eval()\n",
    "print(\"ResNet18 Architecture:\\n\", resnet18)\n",
    "\n",
    "# Example of using ResNet18 for inference.\n",
    "# Uncomment the code below if you have an image to test.\n",
    "#\n",
    "# image_path = \"datasets/tintin-meme.jpg\"  # Provide a valid image path\n",
    "# image = Image.open(image_path)\n",
    "#\n",
    "# # Preprocessing: resize, crop, convert to tensor, and normalize.\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "#\n",
    "# input_tensor = preprocess(image)\n",
    "# # Create a mini-batch as expected by the model\n",
    "# input_batch = input_tensor.unsqueeze(0)\n",
    "#\n",
    "# # Perform inference without computing gradients\n",
    "# with torch.no_grad():\n",
    "#     output = resnet18(input_batch)\n",
    "#\n",
    "# print(\"ResNet18 Output:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "\n",
    "In this notebook we learned:\n",
    "- **Part 1:** Basics of PyTorch (creating tensors, basic ops, and checking for GPU).\n",
    "- **Part 2:** Neural network implementations:\n",
    "  - A custom network built with `nn.Module`.\n",
    "  - An established architecture (LeNet).\n",
    "  - How to load and use a pretrained network (ResNet18)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
