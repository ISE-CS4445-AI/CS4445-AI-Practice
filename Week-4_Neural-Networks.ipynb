{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ISE-CS4445-AI/CS4445-AI-Practice/blob/staging/Week-4_Neural-Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-0AHjZamcZC"
      },
      "source": [
        "# Week 4 Exercise Notebook: Neural Networks with PyTorch\n",
        "\n",
        "This notebook is split into two parts:\n",
        "1. **Introduction to PyTorch** – Learn the basics.\n",
        "2. **Neural Network Implementations** – Build custom nets, established architectures, and use pretrained networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObyGGcabmcZD"
      },
      "source": [
        "## Part 1: Introduction to PyTorch\n",
        "\n",
        "In this section we cover the basics. We learn how to create and work with tensors. We check for GPU support. Run each cell and follow the instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc_y2v0GmcZD"
      },
      "source": [
        "### 1.1. Importing PyTorch and Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af7gelN5mcZD",
        "outputId": "09add93d-7f38-4290-c6a8-ca951646d828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.5.1+cu124\n",
            "Tensor x: tensor([1, 2, 3])\n",
            "Random Tensor:\n",
            " tensor([[0.8973, 0.2249, 0.2871],\n",
            "        [0.1346, 0.5209, 0.2522],\n",
            "        [0.3061, 0.4159, 0.1114]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Print the PyTorch version\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "\n",
        "# Create a simple tensor\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(\"Tensor x:\", x)\n",
        "\n",
        "# Create a random tensor with shape (3, 3)\n",
        "rand_tensor = torch.rand(3, 3)\n",
        "print(\"Random Tensor:\\n\", rand_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AclUXbx-mcZD"
      },
      "source": [
        "### 1.2. Basic Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lotjXONmcZE",
        "outputId": "257fd699-7c98-422d-c4d4-386f0155cdbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sum: tensor([4, 6])\n",
            "Element-wise Product: tensor([3, 8])\n"
          ]
        }
      ],
      "source": [
        "# Define two tensors\n",
        "a = torch.tensor([1, 2])\n",
        "b = torch.tensor([3, 4])\n",
        "\n",
        "# Addition\n",
        "sum_ab = a + b\n",
        "print(\"Sum:\", sum_ab)\n",
        "\n",
        "# Element-wise multiplication\n",
        "prod_ab = a * b\n",
        "print(\"Element-wise Product:\", prod_ab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjBPBdYRmcZE"
      },
      "source": [
        "### 1.3. Check for GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4wck1DbmcZE",
        "outputId": "cde978d7-f3a4-4585-d514-c74a5eb35a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Tensor x on device: tensor([1, 2, 3], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Choose the device: use GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Move tensor 'x' to the selected device\n",
        "x = x.to(device)\n",
        "print(\"Tensor x on device:\", x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbNb25xlmcZE"
      },
      "source": [
        "## Part 2: Neural Network Implementations\n",
        "\n",
        "In this section we build and experiment with neural networks.\n",
        "We cover:\n",
        "- A custom neural network.\n",
        "- An established architecture (LeNet).\n",
        "- A pretrained network (ResNet18)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWU0ey2EmcZE"
      },
      "source": [
        "### 2.1. Custom Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5attw2TmcZE",
        "outputId": "f50eeb90-4f9d-4d59-a043-6ea01d9a6839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CustomNet Architecture:\n",
            " CustomNet(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a simple feed-forward network for, e.g., MNIST (28x28 images flattened to 784)\n",
        "class CustomNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(CustomNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input tensor\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of CustomNet\n",
        "model = CustomNet(input_size=784, hidden_size=128, num_classes=10)\n",
        "print(\"CustomNet Architecture:\\n\", model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g-_mggvmcZE"
      },
      "source": [
        "### 2.2. Established Architecture: LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpl6Vzn0mcZE",
        "outputId": "461383ca-6994-470e-b9d4-af07e2a4ca9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LeNet Architecture:\n",
            " LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# LeNet was designed for handwritten digit recognition.\n",
        "# This is a simplified implementation.\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # Convolution layers\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        # Max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply first conv + ReLU + pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # Apply second conv + ReLU + pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # Flatten the tensor for fully connected layers\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of LeNet\n",
        "lenet_model = LeNet()\n",
        "print(\"LeNet Architecture:\\n\", lenet_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL9iPX4CmcZE"
      },
      "source": [
        "### 2.3. Pretrained Networks: ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAB1ZpqsmcZE",
        "outputId": "2604a438-1b2a-4109-90d5-6f614bbf5f13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet18 Architecture:\n",
            " ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "ResNet18 Output:\n",
            " tensor([[-2.7560e+00, -3.9821e+00, -2.3339e+00, -1.8320e+00, -2.4144e+00,\n",
            "         -5.7511e-01, -8.7185e-01, -9.3433e-01, -3.6243e+00, -1.0450e+00,\n",
            "         -2.0340e+00, -1.6634e+00, -3.0891e+00, -2.8899e+00,  4.2373e-02,\n",
            "         -2.6655e+00, -1.7762e+00, -3.7585e+00, -2.0714e+00, -1.1954e+00,\n",
            "         -4.6911e+00, -3.3863e+00, -2.8805e+00, -4.0064e+00, -2.2617e+00,\n",
            "         -1.5218e+00, -2.8420e+00, -2.0940e+00, -2.2534e+00, -4.7258e+00,\n",
            "         -1.8255e+00, -1.9410e+00, -1.8178e+00, -3.1590e+00, -1.4541e+00,\n",
            "         -1.7576e+00, -7.4690e-01, -7.1417e-01, -1.0701e+00, -2.9362e+00,\n",
            "         -4.3095e+00, -1.7214e+00, -4.7299e+00, -2.0133e+00, -3.4240e+00,\n",
            "         -6.9762e-02, -2.2487e+00, -1.1695e+00, -4.4170e+00, -1.8413e+00,\n",
            "         -1.0251e+00, -4.1273e-01, -2.7791e+00, -1.4734e+00, -3.9660e+00,\n",
            "         -2.7439e+00, -3.2657e+00, -2.4813e+00, -1.9345e+00, -1.7449e+00,\n",
            "         -1.0492e+00, -1.7639e+00, -2.3581e+00, -1.2315e+00, -1.3219e+00,\n",
            "         -2.5609e+00,  3.8317e-01, -2.0080e+00, -2.0122e+00,  2.0095e-01,\n",
            "         -2.8808e+00,  3.2385e+00, -1.6260e+00, -2.0422e+00, -2.9601e+00,\n",
            "         -4.1656e+00, -2.1148e+00, -3.3866e+00,  1.7698e+00, -7.7986e-01,\n",
            "         -4.4598e+00, -5.0522e+00, -3.3086e+00, -4.2671e+00, -4.9355e+00,\n",
            "         -2.5458e+00, -3.6097e+00, -2.0823e+00, -3.4120e-01, -4.4249e+00,\n",
            "         -4.7662e+00, -1.4341e-01, -2.7554e+00, -1.9182e+00, -3.0986e+00,\n",
            "         -2.8584e+00, -2.3847e+00, -5.7325e+00, -4.1737e+00, -4.6039e+00,\n",
            "         -4.8351e+00, -3.1293e+00, -2.1069e+00,  5.8608e-01, -3.1813e+00,\n",
            "         -2.0643e+00, -2.7478e+00,  1.3328e+00, -2.8912e+00, -4.5368e+00,\n",
            "          1.8801e-01,  3.2169e+00, -1.4878e+00, -1.9708e+00, -2.2069e+00,\n",
            "         -1.2862e+00, -1.4419e+00, -2.0176e+00, -1.3099e+00, -4.1985e+00,\n",
            "         -3.0718e+00, -3.4240e+00,  3.9693e-01, -3.0961e+00, -1.9735e+00,\n",
            "         -1.5859e+00, -9.0320e-02, -4.6604e+00, -4.1567e+00, -3.6276e+00,\n",
            "         -4.6427e+00, -1.3128e+00, -1.7796e+00, -1.6660e+00, -3.2838e+00,\n",
            "         -2.5983e+00, -1.9482e+00, -3.4663e+00, -3.5031e+00, -4.6870e+00,\n",
            "         -3.8869e+00, -4.7529e+00, -4.1933e+00, -5.1866e+00, -4.0652e+00,\n",
            "         -4.3284e+00, -6.2003e+00, -4.2228e+00, -1.3414e+00, -1.9566e+00,\n",
            "         -2.2652e+00,  9.7239e-01, -5.6571e-01, -4.1394e-01,  1.2262e-01,\n",
            "          1.9052e+00, -2.5025e-01,  6.9750e-01, -1.4538e+00, -8.2375e-01,\n",
            "          5.8294e-01,  9.9365e-01, -1.6302e+00,  2.2592e+00, -1.1182e-01,\n",
            "         -9.0571e-01, -1.9408e+00, -1.8914e+00, -6.6217e-01,  7.6361e-01,\n",
            "         -1.1652e-01, -2.2498e+00,  5.4751e-01, -1.8068e+00, -1.7059e+00,\n",
            "         -1.2686e-01, -2.9007e-01,  7.3611e-01,  3.3288e-02, -9.1980e-04,\n",
            "         -5.5422e-01, -1.7194e-01, -3.1224e+00, -5.7138e-01, -2.7555e+00,\n",
            "         -6.4462e-01, -1.5474e+00,  1.6869e+00, -2.2984e+00, -1.8340e+00,\n",
            "         -7.8085e-01, -3.9935e+00, -1.8096e+00, -2.2730e-01,  3.9302e-02,\n",
            "         -4.3129e-01, -1.8913e+00,  4.5213e-01,  1.9034e-01, -1.4305e+00,\n",
            "          9.2852e-01, -1.7565e-01,  9.7326e-01, -8.7548e-02,  1.5871e-01,\n",
            "         -2.5488e+00, -1.2728e+00, -6.1596e-01, -1.4474e+00, -2.1254e+00,\n",
            "         -1.2821e+00, -1.5428e-01, -1.0927e+00, -1.2031e+00, -1.4683e-01,\n",
            "         -2.0508e+00,  4.9605e-01, -2.4106e-01, -1.4850e+00, -1.0471e-01,\n",
            "          2.5414e-01, -7.9695e-01, -2.0253e-01, -1.5659e+00,  9.7837e-02,\n",
            "         -2.3893e+00, -4.2524e-01, -2.3659e+00, -4.4304e-01,  1.0375e+00,\n",
            "         -2.1091e+00, -4.4105e-01, -1.2058e+00,  1.5622e+00, -4.9765e-01,\n",
            "         -2.7108e-01, -2.5574e+00, -3.6229e+00, -1.4565e-01, -1.4006e+00,\n",
            "         -1.0222e+00, -1.8267e+00,  1.2606e+00,  1.2423e+00, -1.0701e+00,\n",
            "         -8.9165e-01,  5.0688e-01,  5.7837e-01, -1.0573e+00, -4.3469e-01,\n",
            "         -9.1230e-01,  1.8666e+00, -2.0853e-02, -1.4395e+00,  1.7717e+00,\n",
            "         -2.4498e-01,  3.1889e-01, -2.8125e-01, -2.3795e+00, -1.1339e+00,\n",
            "         -1.2623e+00, -4.7141e-02, -1.7440e+00, -3.0546e+00, -2.5414e+00,\n",
            "         -1.8808e+00, -3.2421e+00, -2.6528e+00, -1.4996e+00, -2.7491e+00,\n",
            "         -2.2163e+00, -4.0812e+00, -3.2362e+00, -2.1869e+00, -2.8250e+00,\n",
            "         -1.4066e+00, -1.4066e+00, -3.6689e+00, -3.9516e+00, -3.0456e+00,\n",
            "         -3.4449e+00, -4.6158e-01,  1.0262e+00,  1.1175e+00, -2.1599e+00,\n",
            "         -1.1318e+00, -1.3737e+00, -3.2979e+00, -1.3336e+00, -2.5513e+00,\n",
            "         -1.9293e+00, -4.6615e-01,  1.8079e+00, -2.8364e-01, -5.1109e+00,\n",
            "         -4.3527e+00, -3.3175e+00, -2.6473e+00, -4.1908e+00, -1.5891e+00,\n",
            "         -9.2768e-01, -2.5033e+00, -1.3137e+00, -8.4697e-01, -1.2483e+00,\n",
            "         -2.4564e+00,  2.1274e+00, -1.5516e+00, -8.3679e-01, -5.9599e-01,\n",
            "          1.8331e+00, -2.8882e+00, -4.2306e+00, -1.6818e+00,  1.0347e+00,\n",
            "         -1.5501e+00, -2.0318e+00, -1.9639e+00, -1.2097e+00,  9.2935e-02,\n",
            "         -1.0011e+00, -3.1142e+00, -2.0032e+00,  1.6876e-01, -2.8158e+00,\n",
            "         -1.6726e-01, -2.2754e-02, -3.0595e+00, -3.4634e+00, -1.0864e+00,\n",
            "         -1.8426e+00, -1.4735e+00, -2.2064e+00,  4.5978e-01, -2.6039e+00,\n",
            "         -3.0854e+00, -6.2172e+00, -6.5639e-01,  5.4242e-01, -1.9816e+00,\n",
            "         -1.2015e+00, -2.6955e+00, -3.9113e+00, -1.3471e+00, -2.1110e+00,\n",
            "         -1.2092e+00, -2.0865e+00, -1.8732e+00, -3.9314e+00, -3.7835e+00,\n",
            "         -4.2249e+00, -3.2272e+00, -3.4118e+00, -3.5147e+00, -2.5817e+00,\n",
            "         -2.2936e+00, -4.6567e-01, -1.3954e+00, -1.0108e+00, -1.8169e+00,\n",
            "         -1.1588e+00,  5.2020e-01, -2.0073e+00, -1.8363e+00, -1.4704e+00,\n",
            "         -1.0722e+00, -4.8732e-01,  1.6107e+00, -1.3336e+00, -2.5214e-01,\n",
            "         -1.3227e+00,  6.1525e-01, -2.4075e+00, -9.5670e-01, -2.2208e+00,\n",
            "         -1.6343e+00,  3.2604e-01, -2.5649e-01, -1.5972e-02, -1.0809e+00,\n",
            "         -1.3096e+00, -2.1104e+00, -2.0610e+00, -2.0684e+00, -1.6217e+00,\n",
            "         -2.2342e+00, -2.6842e+00, -4.1635e+00, -2.0063e+00, -2.1867e+00,\n",
            "         -3.2937e+00, -2.5558e+00, -1.5395e+00, -3.5354e+00, -3.7954e+00,\n",
            "         -3.7777e+00, -3.2634e+00, -5.1462e+00,  1.8059e+00,  3.8055e-01,\n",
            "         -1.9718e+00,  8.7252e-01,  5.8155e+00, -4.3763e+00, -2.3919e+00,\n",
            "          1.0363e+00,  1.8118e+00,  1.6900e+00, -2.6753e+00,  4.6057e+00,\n",
            "         -2.5111e+00,  4.4057e+00,  2.4158e+00,  1.7942e+00,  3.3034e+00,\n",
            "          1.7639e+00,  4.4844e+00,  3.1650e+00,  2.4037e+00,  6.7466e+00,\n",
            "          2.7990e+00, -4.7727e-01,  3.4601e+00,  2.3365e+00,  3.4704e+00,\n",
            "         -2.8426e-01,  3.6970e+00,  3.6855e+00,  3.0975e-01,  5.2202e-01,\n",
            "          3.1958e+00,  1.5775e-01,  2.7044e+00,  9.5620e-01,  3.1713e+00,\n",
            "          2.3237e+00, -1.5267e+00, -1.0436e+00,  1.8829e-01, -1.5647e+00,\n",
            "          1.1576e+00,  9.8507e-01, -3.3913e-01,  5.0703e+00,  3.0668e+00,\n",
            "          2.8866e+00,  5.0426e+00,  4.3326e-01,  1.5386e+00, -3.0000e+00,\n",
            "         -1.9854e+00, -1.2571e+00, -1.4249e+00,  1.9474e+00,  5.6300e+00,\n",
            "         -4.6209e-03,  1.9619e+00,  1.2518e+00,  1.9814e+00,  5.1495e+00,\n",
            "         -4.1191e+00,  1.7258e+00, -9.7951e-02,  1.8181e+00,  1.1787e+00,\n",
            "          2.4820e+00, -2.0082e+00,  6.4149e-01,  1.4292e+00,  2.8886e-01,\n",
            "          1.6864e+00, -1.7689e+00, -9.1881e-01,  1.9786e+00, -3.1333e-01,\n",
            "         -1.8639e+00,  2.5986e+00,  2.5869e+00,  6.2512e+00, -1.3557e+00,\n",
            "          2.4794e+00,  6.7711e+00,  2.1006e+00, -2.3407e+00,  3.8937e-01,\n",
            "          2.4705e+00,  5.1031e+00,  2.8441e+00,  1.2254e+00,  1.2796e+00,\n",
            "         -1.4025e+00,  1.2261e+00,  1.2690e+00,  8.5121e-01,  1.5611e+00,\n",
            "          6.4373e-01,  3.4446e+00,  1.9434e+00,  1.5690e+00,  1.4751e+00,\n",
            "         -2.2669e+00,  8.5088e-01,  6.5123e-01,  7.5299e-01,  5.4406e+00,\n",
            "          2.0844e+00, -1.7810e+00,  9.4007e-01,  9.0131e-01,  1.3856e+00,\n",
            "         -6.6742e-01, -1.5454e+00,  3.0069e+00,  2.7247e+00,  4.4232e+00,\n",
            "          2.0688e+00,  2.2140e+00,  3.1683e-01,  5.6130e-02,  1.7779e+00,\n",
            "          2.8114e+00,  3.1771e+00, -5.3245e-02,  1.6975e+00,  6.2203e-01,\n",
            "         -1.7907e+00,  1.6937e+00,  2.2687e+00,  3.1911e+00,  2.9939e+00,\n",
            "          3.3479e+00,  4.5636e-01, -1.1944e+00, -2.6122e+00,  1.4812e+00,\n",
            "         -2.9347e-01, -2.3406e+00, -5.8417e-01, -1.9799e+00,  4.7726e+00,\n",
            "         -1.7204e+00,  2.7901e+00,  5.2834e+00,  2.3576e+00, -2.3623e-01,\n",
            "          1.9019e+00,  6.8166e+00,  6.7445e-01, -1.2608e+00,  8.0313e+00,\n",
            "          9.2236e-01,  5.1889e+00,  2.0358e+00,  3.7298e+00, -4.2436e+00,\n",
            "          1.4792e+00,  2.6579e+00, -1.2424e-01,  8.0401e-01,  1.3237e+00,\n",
            "          5.2010e-01,  6.0880e-01,  1.1449e+00,  1.7763e+00,  4.7665e-01,\n",
            "          6.0126e+00,  1.9065e+00,  1.0213e+00,  1.0921e+00,  1.2169e+00,\n",
            "          1.7057e+00,  3.7623e+00,  6.4812e-01, -2.2438e+00, -2.9977e-01,\n",
            "         -7.9111e-01, -7.8034e-01,  2.1744e+00,  1.0995e+00,  2.4700e+00,\n",
            "         -1.2169e+00, -2.5252e+00,  1.5723e-01,  1.6130e+00,  1.4575e+00,\n",
            "          6.1361e+00, -1.6889e+00,  2.5535e+00,  9.3242e-01,  5.9803e+00,\n",
            "          1.5027e+00,  5.7977e+00,  3.3723e+00,  3.3496e+00,  1.7088e+00,\n",
            "         -4.6296e-01,  2.4844e+00,  5.3107e-02, -1.1017e+00,  9.8837e-01,\n",
            "          4.2459e+00,  3.4212e-02,  1.2969e+00, -9.0429e-01,  2.1404e+00,\n",
            "          2.9152e+00,  3.3754e+00,  5.0796e-01,  4.9631e+00,  8.3448e-02,\n",
            "          7.8872e+00,  9.1774e+00,  7.6225e-02,  2.3132e+00,  1.0285e+00,\n",
            "          1.6094e-01, -1.6017e+00,  1.8872e+00,  2.8123e+00,  3.3848e+00,\n",
            "          5.4884e+00, -1.9255e+00,  6.9716e-01,  1.9641e+00,  4.0071e+00,\n",
            "         -9.7982e-01,  2.3056e+00, -1.3162e+00, -9.6721e-01,  3.7773e+00,\n",
            "         -7.1128e-01,  3.1983e+00,  7.1489e-01,  1.6946e+00, -2.9005e+00,\n",
            "          6.5247e-01,  3.9114e+00,  2.5151e+00,  3.5941e+00,  3.8370e+00,\n",
            "          1.5447e+00,  3.2399e+00,  2.7683e+00,  1.4857e+00,  1.3630e+00,\n",
            "          2.3739e-01,  1.5876e+00, -3.3803e-01,  7.3434e-01, -2.6908e+00,\n",
            "          5.1461e+00,  8.1912e-01,  6.6318e-01,  6.6960e-01,  5.9375e-01,\n",
            "          4.6730e+00, -8.9070e-01, -3.0207e-01,  2.8940e-02,  5.9411e-01,\n",
            "          2.8282e-01, -2.4866e+00,  7.7936e-01, -7.1909e-01,  1.8396e+00,\n",
            "          1.9875e+00, -3.0646e-01, -1.3531e+00, -1.9292e-01,  1.5186e+00,\n",
            "          5.0314e-01,  2.3997e-01,  6.5094e-01,  3.6379e+00,  3.8326e+00,\n",
            "          4.0908e+00, -4.8118e-01,  4.0391e-01,  2.0339e+00, -8.4567e-01,\n",
            "          4.2713e+00,  2.8045e+00,  1.0365e-01,  1.5599e+00,  4.4163e+00,\n",
            "         -2.4652e-01, -8.4548e-01,  4.9955e-01,  4.6016e+00, -1.2053e+00,\n",
            "         -2.1669e+00,  4.0243e+00,  4.2603e+00,  2.1518e+00, -2.9290e+00,\n",
            "          1.3683e+00,  4.3015e+00,  3.7887e+00, -6.3011e-01,  2.5588e+00,\n",
            "          1.7134e+00,  1.3401e+00,  1.3425e+00,  3.3851e-02,  1.2715e+00,\n",
            "         -2.9834e-01, -4.5276e+00,  3.3858e+00, -1.8359e+00,  5.5496e+00,\n",
            "          2.5313e+00,  3.8300e+00,  1.6862e+00,  6.0744e-01,  4.8077e+00,\n",
            "         -4.9099e-01,  2.4175e+00, -2.3967e+00, -1.6726e+00,  1.2926e+00,\n",
            "          2.3320e+00,  5.1026e+00,  2.6615e+00, -9.7321e-01, -7.6179e-01,\n",
            "          2.3137e+00, -6.6610e-01,  7.4959e-01,  4.2486e-01,  1.1481e+00,\n",
            "         -1.5221e-01,  3.9736e+00,  1.4015e+00,  3.6422e+00, -5.5190e-01,\n",
            "          6.4399e-01,  2.4047e+00,  9.0865e-02, -1.9470e+00,  3.0229e+00,\n",
            "          2.6177e+00,  3.4263e+00,  1.4990e+00,  1.2030e+00, -2.5658e-01,\n",
            "          2.4474e+00,  1.5926e+00,  3.9047e+00,  1.0168e+00,  2.7690e+00,\n",
            "          1.7658e+00, -1.0669e+00,  3.0834e+00, -5.2204e-02,  8.4765e-01,\n",
            "          3.6543e-01,  1.4333e+00,  3.2133e+00,  2.5902e+00,  7.6059e-01,\n",
            "          2.2940e+00,  3.0708e+00,  2.0774e+00,  3.3239e+00,  3.8085e+00,\n",
            "          1.5776e+00, -3.0038e-01,  4.4237e+00,  3.2465e+00,  5.2336e+00,\n",
            "          1.6265e+00,  2.1090e+00,  3.9815e+00,  2.1309e+00,  1.8502e+00,\n",
            "          2.0220e+00,  2.2008e+00,  4.5288e-01,  3.3508e+00,  3.2567e+00,\n",
            "         -7.6648e-01,  2.5421e+00,  3.0378e+00,  1.2940e+00,  2.9564e+00,\n",
            "          6.3811e-02,  3.1516e+00,  3.4771e+00,  3.3796e+00,  1.3855e+00,\n",
            "         -8.3759e-01,  1.1342e+00,  9.5884e-01,  1.2999e+00,  6.3051e+00,\n",
            "          3.5475e+00,  5.6579e-01,  3.9628e+00,  3.0044e+00,  1.2605e+00,\n",
            "          4.2291e+00,  5.9399e-01, -2.5463e+00, -2.5649e+00,  2.7562e+00,\n",
            "          1.6457e+00,  3.5035e-01,  2.8207e-01,  4.8861e-01, -7.8993e-01,\n",
            "         -9.3982e-01,  8.9843e-01,  5.0721e-01,  1.5330e+00, -2.4864e+00,\n",
            "         -2.3780e+00,  3.3984e-01, -2.9493e+00,  1.0742e+00,  4.1002e+00,\n",
            "         -7.4342e-01, -2.6296e+00,  3.4923e+00,  4.7677e+00,  6.3081e-01,\n",
            "         -3.1849e+00,  2.3677e+00,  6.4549e-01, -4.6699e-01,  2.0106e+00,\n",
            "          2.6378e+00,  8.5519e-01, -2.6946e+00, -2.6946e+00, -1.6492e-01,\n",
            "          8.2173e-01,  3.1479e+00,  3.0155e+00,  2.7821e+00, -2.4908e+00,\n",
            "          2.2814e+00,  4.1029e+00,  1.3224e+00,  1.1309e-01,  3.1186e+00,\n",
            "          2.7464e+00,  3.0192e+00, -4.1542e-01,  3.3109e+00,  1.1048e+00,\n",
            "          7.8354e-01,  3.2486e+00,  3.1551e+00, -3.9566e+00,  3.4392e+00,\n",
            "          2.2043e+00, -1.3655e+00,  2.4356e+00, -2.4227e+00,  3.8580e+00,\n",
            "          3.8508e+00,  5.7623e+00,  1.1028e+00,  7.2403e-01, -9.9136e-01,\n",
            "          3.2741e+00,  4.5444e-01,  1.5939e+00,  4.5242e+00,  7.8586e-01,\n",
            "          2.1184e+00, -2.4329e+00,  9.1362e-01,  1.1030e+00,  1.2760e-01,\n",
            "          2.1626e+00,  2.1399e+00, -1.8146e+00,  7.5852e-01,  2.6454e+00,\n",
            "          1.0900e+00,  1.9679e+00,  3.8960e+00,  1.3034e+00, -1.3485e+00,\n",
            "         -1.4784e+00,  2.7726e+00,  2.5454e-01, -6.0421e-01,  5.3506e+00,\n",
            "          3.8793e+00, -8.2633e-01,  7.0204e+00,  3.2805e+00,  5.0763e+00,\n",
            "         -1.6352e+00,  2.9775e-01,  4.2437e+00,  9.2288e-01,  1.8079e+00,\n",
            "          1.4842e+00,  1.0862e-02,  4.4933e-01,  2.7268e+00, -4.0667e-01,\n",
            "          8.4376e-01,  8.5399e-01,  2.8770e+00, -2.6497e+00, -4.0566e-01,\n",
            "          3.4707e+00, -1.0679e-01, -1.8919e+00, -2.1704e+00, -1.2493e+00,\n",
            "         -7.7416e-01,  8.3115e+00,  1.5258e+01,  4.5771e+00,  4.6655e+00,\n",
            "          1.8633e+00,  1.3666e+01,  7.0830e+00, -3.4970e-01, -2.7956e+00,\n",
            "         -2.0017e+00, -3.1684e+00, -1.9487e+00, -1.7205e+00,  1.9850e+00,\n",
            "         -3.2410e+00, -3.0345e+00,  2.5419e-02, -2.3847e+00,  5.9918e-01,\n",
            "         -2.1354e+00, -1.0040e+00, -1.6952e+00, -7.5001e-01, -6.7760e-01,\n",
            "         -2.5776e-01, -1.4181e-01,  1.7463e-01, -6.1946e-01, -6.1622e-01,\n",
            "         -1.2592e+00, -3.3377e+00, -2.5926e+00,  7.6159e-02, -1.8596e+00,\n",
            "         -3.5039e-01, -2.4213e-01, -1.1679e+00, -1.1922e+00,  3.4127e+00,\n",
            "         -1.5350e+00,  4.4460e-01, -7.3830e-01, -1.8546e-01, -2.0990e+00,\n",
            "         -6.4451e-01,  7.1925e-01, -1.2000e+00, -1.5362e+00, -2.9711e+00,\n",
            "         -3.8219e+00,  1.9930e+00,  7.4265e-01,  2.4241e+00,  2.0880e+00,\n",
            "         -7.4472e-02,  7.8827e-01, -9.8578e-01, -1.5575e+00, -1.3420e+00,\n",
            "         -9.6876e-01, -3.4730e+00, -8.7102e-01, -8.1146e-01, -2.4826e+00,\n",
            "         -1.1404e+00, -4.8132e-01, -1.4430e-01,  9.6822e-01,  4.2847e+00,\n",
            "         -1.7614e+00, -1.1158e+00,  1.1287e+00, -1.0899e-01, -3.7451e+00,\n",
            "         -3.0067e+00, -3.3147e+00, -3.5175e+00, -1.2106e+00, -3.8527e+00,\n",
            "         -2.9947e+00, -2.9083e+00, -2.5843e+00, -1.0457e+00,  2.6595e+00]])\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load a pretrained ResNet18 model from torchvision.\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "# Set the model to evaluation mode\n",
        "resnet18.eval()\n",
        "print(\"ResNet18 Architecture:\\n\", resnet18)\n",
        "\n",
        "# Example of using ResNet18 for inference.\n",
        "# Uncomment the code below if you have an image to test.\n",
        "#\n",
        "image_path = \"./tintin-meme.jpg\"  # Provide a valid image path\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Preprocessing: resize, crop, convert to tensor, and normalize.\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(image)\n",
        "# Create a mini-batch as expected by the model\n",
        "input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "# Perform inference without computing gradients\n",
        "with torch.no_grad():\n",
        "    output = resnet18(input_batch)\n",
        "\n",
        "print(\"ResNet18 Output:\\n\", output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bez3FCWxreZa",
        "outputId": "06995992-a107-449c-dea0-908633b438b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([917])\n"
          ]
        }
      ],
      "source": [
        "# Get the predicted class index\n",
        "_, predicted_idx = torch.max(output, 1)\n",
        "print(predicted_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM9RDBxVmcZE"
      },
      "source": [
        "## Wrap-Up\n",
        "\n",
        "In this notebook we learned:\n",
        "- **Part 1:** Basics of PyTorch (creating tensors, basic ops, and checking for GPU).\n",
        "- **Part 2:** Neural network implementations:\n",
        "  - A custom network built with `nn.Module`.\n",
        "  - An established architecture (LeNet).\n",
        "  - How to load and use a pretrained network (ResNet18)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
