{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Feature Engineering Tutorial\n",
    "\n",
    "Welcome to this **guided demo and exercise** notebook. In this tutorial, we'll explore:\n",
    "\n",
    "1. **Loading a small dataset** with missing values, outliers, and categorical columns.  \n",
    "2. **Identifying** and **handling** missing data (e.g., dropping or imputing).  \n",
    "3. **Detecting** outliers and applying a basic clipping strategy.  \n",
    "4. **Encoding** categorical features.  \n",
    "5. **Creating** new features from existing columns.\n",
    "\n",
    "There is a sample CSV file named **`sample_data.csv`** in the same repo, representing a small user dataset with columns like:\n",
    "\n",
    "- `user_id`: an identifier (might not be used in modeling)\n",
    "- `age`: numeric, can contain missing values\n",
    "- `income`: numeric, can have outliers\n",
    "- `city`: categorical\n",
    "- `purchases`: numeric (count of purchases)\n",
    "- `score`: some numeric rating like credit score.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Load the Dataset\n",
    "\n",
    "We'll define a short function to read the CSV into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./datasets/week-2_sample_data.csv\" \n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Reads a CSV, returns the DataFrame.\n",
    "    Columns: ['user_id','age','income','city','purchases','score']\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    return df\n",
    "\n",
    "# Demo\n",
    "if __name__ == \"__main__\":\n",
    "    df_raw = load_data()\n",
    "    display(df_raw.head(10))\n",
    "    print(df_raw.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Data\n",
    "\n",
    "### 3.1 Identify Missing Values\n",
    "\n",
    "Check how many `NaN` or `None` entries each column has, and see if there's a strategy (drop vs. fill).\n",
    "\n",
    "**Practice**:  \n",
    "1. Print `df.isna().sum()` to see missing counts.  \n",
    "2. Decide how to handle missing `age` or other columns.\n",
    "\n",
    "*(No right/wrong approach, but let’s do something simple for demonstration.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing(df):\n",
    "    \"\"\"\n",
    "    Example function that:\n",
    "    1. Fills or drops missing values\n",
    "    2. Demonstrates a simple approach for missing 'age'\n",
    "    \"\"\"\n",
    "    # TODO: fill in your approach\n",
    "    # e.g. fill 'age' with median:\n",
    "    median_age = df['age'].median()\n",
    "    df['age'].fillna(median_age, inplace=True)\n",
    "    \n",
    "    # If 'city' is missing, maybe fill with 'Unknown':\n",
    "    df['city'].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_demo = load_data()\n",
    "    print(\"Before handling missing values:\")\n",
    "    print(df_demo.isna().sum())\n",
    "    \n",
    "    df_demo = handle_missing(df_demo)\n",
    "    print(\"\\nAfter handling missing values:\")\n",
    "    print(df_demo.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't panic!\n",
    "The error above is expected and part of the learning process. If you look at the error message, it says that it cannot convert values in 'age' to a numeric type. This is because the missing values represented as 'nan'/'na' are present. This is common in the real world. To handle this, we can do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing(df):\n",
    "    \"\"\"\n",
    "    Example function that:\n",
    "    1. Fills or drops missing values\n",
    "    2. Demonstrates a simple approach for missing 'age'\n",
    "    \"\"\"\n",
    "    # Convert 'age' to numeric, forcing invalid strings to NaN\n",
    "    df['age'] = pd.to_numeric(df_demo['age'], errors='coerce')\n",
    "\n",
    "    # Explanation:\n",
    "    #   - This will turn '12' -> 12, 'na' -> NaN, '' -> NaN, etc.\n",
    "    #   - The column becomes float64 or int64 if no decimals.\n",
    "\n",
    "    # e.g. fill 'age' with median:\n",
    "    median_age = df['age'].median()\n",
    "    df['age'].fillna(median_age, inplace=True)\n",
    "    \n",
    "    # If 'city' is missing, maybe fill with 'Unknown':\n",
    "    df['city'].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_demo = handle_missing(df_demo)\n",
    "print(\"\\nAfter handling missing values:\")\n",
    "print(df_demo.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Detecting & Handling Outliers\n",
    "\n",
    "We’ll assume `income` might have outliers. We can do:\n",
    "\n",
    "1. Plot a histogram or boxplot to see distribution.  \n",
    "2. Decide on a cap or method (e.g., clip at 95th percentile).\n",
    "\n",
    "**Practice**:  \n",
    "- Use `df['income'].describe()` or a boxplot.  \n",
    "- Clip incomes above e.g. 100000 to exactly 100000, if that’s your chosen approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_outliers(df, col='income', cap=100000):\n",
    "    \"\"\"\n",
    "    Example function that clips 'income' at a certain cap.\n",
    "    \"\"\"\n",
    "    # TODO: implement your outlier strategy\n",
    "    df[col] = np.where(df[col] > cap, cap, df[col])\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_demo = load_data()\n",
    "    # A quick distribution check\n",
    "    df_demo['income'].hist(bins=20)\n",
    "    plt.title(\"Income Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "    # clip approach\n",
    "    df_demo = clip_outliers(df_demo, col='income', cap=100000)\n",
    "    # see result\n",
    "    df_demo['income'].hist(bins=20)\n",
    "    plt.title(\"Income Dist after clipping\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Encoding Categorical Features\n",
    "\n",
    "- **Label Encoding** or **One-Hot**: `pd.get_dummies()`.\n",
    "- If `df['city']` is something like `[New York, Paris, Tokyo]`, we can do: `df = pd.get_dummies(df, columns=['city'])`.\n",
    "\n",
    "**Practice**:  \n",
    "- Create a function that one-hot encodes `city`.  \n",
    "- Or do label encoding if you prefer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_city(df):\n",
    "    \"\"\"\n",
    "    Example: one-hot encode 'city'\n",
    "    This might create columns city_New York, city_Paris, city_Tokyo, etc.\n",
    "    \"\"\"\n",
    "    # TODO: e.g.: df = pd.get_dummies(df, columns=['city'], drop_first=False)\n",
    "    df = pd.get_dummies(df, columns=['city'], drop_first=False)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_demo = load_data()\n",
    "    df_demo = encode_city(df_demo)\n",
    "    display(df_demo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Creating New Features\n",
    "\n",
    "Examples:\n",
    "- **`df['family_size'] = df['SibSp'] + df['Parch'] + 1`** (like Titanic).  \n",
    "- **`df['purchases_per_income'] = df['purchases'] / df['income']`** (user spending rate).\n",
    "- **`df['log_score'] = np.log1p(df['score'])`** if `score` is large or skewed.\n",
    "\n",
    "**Practice**:  \n",
    "- Add a new feature based on existing columns. \n",
    "- Inspect correlation or distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Example: create 'purchases_per_income'\n",
    "    \"\"\"\n",
    "    # TODO: df['purchases_per_income'] = df['purchases'] / (df['income'] + 1)\n",
    "    df['purchases_per_income'] = df['purchases'] / (df['income'] + 1)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_demo = load_data()\n",
    "    df_demo = create_features(df_demo)\n",
    "    display(df_demo.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Putting It All Together: A Pipeline\n",
    "\n",
    "We can define a single function that:\n",
    "\n",
    "1. **Loads** data\n",
    "2. **Handles** missing\n",
    "3. **Clips** outliers\n",
    "4. **Encodes** categories\n",
    "5. **Creates** new features\n",
    "6. Returns the final cleaned DataFrame\n",
    "\n",
    "Use the sub-steps from above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    df = load_data()\n",
    "    df = handle_missing(df)\n",
    "    df = clip_outliers(df, col='income', cap=100000)\n",
    "    df = encode_city(df)\n",
    "    df = create_features(df)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    final_df = preprocess_data()\n",
    "    display(final_df.head())\n",
    "    print(final_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "- **Scale** numeric columns (e.g., StandardScaler) if training a model.  \n",
    "- **Split** train/test, confirm if new features help.  \n",
    "- Possibly store the cleaned data: `final_df.to_csv(\"cleaned_data.csv\", index=False)` if you want a final artifact.\n",
    "\n",
    "**End of Tutorial**  \n",
    "Feel free to experiment with your own transformations and methods!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
